{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eceae09-a1a2-4ded-9b10-b65aadeacb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2e_taxi_ride_duration_prediction.mlflow_utils import setup_mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f42a6-b948-4366-a4ba-5600eb523b36",
   "metadata": {},
   "source": [
    "# Evaluation Criteria\n",
    "## First steps\n",
    "This Project uses `uv` as en environment manager and `just` as a command runner (instead of makefile). \n",
    "To install run `pip install uv` or `pip install rust-just`.\n",
    "After installing just and uv run `just dev` to install development dependencies or run `just` to see a list of available commands and descriptions\n",
    "\n",
    "## Cloud\n",
    "Prerequisites: \n",
    " - awscli\n",
    " - configured credentials\n",
    "\n",
    "There is a terraform folder. Run\n",
    "```bash\n",
    "terraform init\n",
    "terraform plan\n",
    "terraform apply\n",
    "```\n",
    "to initialize an EC2 instance that grabs the latest container uploaded to ghcr.io with the model and runs it. The `terraform apply` function returns the ip of the ec2 instance.\n",
    "you can then send payloads to the api, for example:\n",
    "```bash\n",
    "curl -X POST http://18.193.115.191:8000/predict \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"PULocationID\": 161, \"DOLocationID\": 236, \"trip_distance\": 2.5}'\n",
    "```\n",
    "and you will get a prediction of the ride duration back."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4722e4-eba3-4dfc-a1cd-b4ad5aa34b47",
   "metadata": {},
   "source": [
    "## Experiment Tracking and model Registry\n",
    "In the module `/e2e_taxi_ride_duration_prediction/mlflow_utils.py` I implemented the setup of model tracking with mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59166528-2793-4cb1-ab5b-222d493a4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/04 21:20:24 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/08/04 21:20:24 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/08/04 21:20:24 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "\u001b[32m2025-08-04 21:20:24.624\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36me2e_taxi_ride_duration_prediction.mlflow_utils\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m56\u001b[0m - \u001b[32m\u001b[1mMLflow tracking URI and experiment set up successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_mlflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfa741-df5f-4d71-a4cd-24d6e59af628",
   "metadata": {},
   "source": [
    "## Workflow Orchestration\n",
    "The workflow is split into flows, subflows and tasks for prefect and can be run on schedule if deployed.\n",
    "As an example the command `just serve-prefect` is defined in the justfile and will serve the baseline training flow, which can be triggered by then running `just train-prefect` or by running `uv run prefect deployment run main/taxi-model-baseline-training`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494bd59-3b48-46be-a2f7-588df6471a51",
   "metadata": {},
   "source": [
    "## Model deployment\n",
    "The model can be built locally with the dockerfile (`just docker-build`). The baseline model is also published to ghrc.io via a Github Action that can be triggered manually.\n",
    "You can run the model locally without needing the repository simply by calling\n",
    "```bash\n",
    "docker run --rm -p 8000:8000 ghcr.io/mircohoehne/taxi-api\n",
    "```\n",
    "or\n",
    "```bash\n",
    "podman run --rm -p 8000:8000 ghcr.io/mircohoehne/taxi-api\n",
    "```\n",
    "if you have podman. If you downloaded the repository there is a just command for building (`just docker-build`) and for running (`just docker-run`).\n",
    "To test payloads you can use the command\n",
    "```bash\n",
    "curl -X POST \"http://localhost:8000/predict\" \\\n",
    "      -H \"Content-Type: application/json\" \\\n",
    "      -d '{\"PULocationID\": 161, \"DOLocationID\": 236, \"trip_distance\": 2.5}'\n",
    "```\n",
    "As stated previously the api can also be deployed to aws by using the provided terraform files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d822629-0d69-4741-aea9-97296c5761f8",
   "metadata": {},
   "source": [
    "## Model Monitoring\n",
    "Monitoring is implemented in `e2e_taxi_ride_duration_prediction/monitoring.py`. \n",
    "Implemented is the ability to generate reports based on current data, reference data and the model used. The generated report contains the metrics from the DataDriftPreset and RegressionPreset by default, to monitor and evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af016da-9d27-4e0b-b004-65ba4f96c966",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "To reproduce the workflow you can run the prefect flow as explained above (or just run `scripts/train_model.py`) and start an mlflow server with\n",
    "```bash\n",
    "mlflow server --backend-store-uri sqlite:///mlruns/mlflow.db --default-artifact-root mlruns --host 0.0.0.0\n",
    "```\n",
    "and check the ui at `localhost:5000`. There you will see the 'taxi_ride_duration_prediction' experiment with one run.\n",
    "If you want to reproduce logging, you can refer to the [monitoring notebook](02_monitoring.ipynb) for an example of the monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac003c-1098-4ca2-b1f4-47062b89d711",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "- The tests can be found in the tests/ folder and you can run them with `just test`.\n",
    "- Ruff was used as a linter and formatter (also checked in pre-commit hooks and Github Actions)\n",
    "- This Project uses Justfile as a Makefile replacement with the same functionality\n",
    "- There are pre-commit hooks, which are defined in `.pre-commit-config.yaml`\n",
    "- There is a automatic CI Pipeline (`.github/workflows/ci.yml`) that is triggered on every pull requests or push on the main branch and a CD Pipeline (`.github/workflows/cd.yml`) which can be triggered to upload a new containerized api that includes the current model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
